#!/usr/bin/env python3
"""
ì„œìš¸ê²½ì œ AI GAMES - í€´ì¦ˆ ìë™ ìƒì„± Lambda í•¨ìˆ˜
BigKinds API â†’ Step1 ìŠ¤í¬ë¦¬ë‹ â†’ Step2 ë¬¸ì œ ì œì‘ â†’ DynamoDB ì €ì¥
"""

import os
import json
import boto3
import requests
from datetime import datetime, timedelta
from pathlib import Path

# ì„¤ì •
AWS_REGION = os.environ.get('AWS_REGION', 'us-east-1')
BEDROCK_MODEL_ID = 'anthropic.claude-3-haiku-20240307-v1:0'  # Claude 3 Haiku (ë¹ ë¥´ê³  ì•ˆì •ì )
DYNAMODB_TABLE = os.environ.get('DYNAMODB_TABLE', 'sedaily-quiz-data')
BIGKINDS_API_KEY = os.environ.get('BIGKINDS_API_KEY')

# AWS í´ë¼ì´ì–¸íŠ¸ (íƒ€ì„ì•„ì›ƒ ì„¤ì •)
from botocore.config import Config

bedrock_config = Config(
    read_timeout=300,  # 5ë¶„
    connect_timeout=60,
    retries={'max_attempts': 3}
)

bedrock = boto3.client('bedrock-runtime', region_name=AWS_REGION, config=bedrock_config)
dynamodb = boto3.resource('dynamodb', region_name=AWS_REGION)


def lambda_handler(event, context):
    """
    Lambda ë©”ì¸ í•¸ë“¤ëŸ¬
    EventBridgeì—ì„œ ë§¤ì¼ ìë™ í˜¸ì¶œ
    """
    print("=" * 60)
    print("ğŸ® ì„œìš¸ê²½ì œ AI GAMES - í€´ì¦ˆ ìë™ ìƒì„± ì‹œì‘")
    print("=" * 60)
    
    max_retries = 2  # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
    
    try:
        # 1. BigKindsì—ì„œ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        articles = fetch_bigkinds_news(count=12)
        
        # 2. Step 1: ê¸°ì‚¬ ìŠ¤í¬ë¦¬ë‹
        screening_result, article_url_maps = step1_screen_articles(articles)
        article_url_map, article_url_map_normalized = article_url_maps
        
        # 3. Step 2: ë¬¸ì œ ì œì‘ (ì¬ì‹œë„ ë¡œì§)
        quiz_data = None
        for attempt in range(max_retries + 1):
            quiz_output = step2_generate_quiz(screening_result, retry_count=attempt, max_retries=max_retries)
            
            # 4. JSON íŒŒì‹±
            quiz_data = parse_quiz_output(quiz_output, article_url_map, article_url_map_normalized)
            
            # 5. í’ˆì§ˆ ê²€ì¦
            is_valid, errors = validate_quiz(quiz_data)
            
            if is_valid:
                print(f"âœ… ì‹œë„ {attempt + 1}ì—ì„œ ì„±ê³µ!")
                break
            else:
                if attempt < max_retries:
                    print(f"âš ï¸ ì‹œë„ {attempt + 1} ì‹¤íŒ¨. ì¬ì‹œë„ ì¤‘...")
                else:
                    raise Exception(f"í’ˆì§ˆ ê²€ì¦ ì‹¤íŒ¨ (ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼): {errors}")
        
        # 6. DynamoDB ì €ì¥
        today = datetime.now().strftime('%Y-%m-%d')
        save_to_dynamodb(quiz_data, today)
        
        print("\n" + "=" * 60)
        print("âœ… ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ!")
        print("=" * 60)
        
        return {
            'statusCode': 200,
            'body': json.dumps({
                'message': 'í€´ì¦ˆ ìƒì„± ì™„ë£Œ',
                'date': today,
                'attempts': attempt + 1,
                'questions': {
                    'BlackSwan': len(quiz_data.get('BlackSwan', [])),
                    'PrisonersDilemma': len(quiz_data.get('PrisonersDilemma', [])),
                    'SignalDecoding': len(quiz_data.get('SignalDecoding', []))
                }
            }, ensure_ascii=False)
        }
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()
        
        return {
            'statusCode': 500,
            'body': json.dumps({
                'error': str(e)
            }, ensure_ascii=False)
        }


def normalize_title(title):
    """ê¸°ì‚¬ ì œëª© ì •ê·œí™” (ë§¤ì¹­ìš©)"""
    import re
    # ê³µë°±, íŠ¹ìˆ˜ë¬¸ì ì œê±°í•˜ê³  ì†Œë¬¸ìë¡œ ë³€í™˜
    normalized = re.sub(r'[^\wê°€-í£]', '', title)
    return normalized.lower()


def convert_newsid_to_sedaily_url(news_id):
    """
    BigKinds news_idë¥¼ ì„œìš¸ê²½ì œ ì›ë¬¸ URLë¡œ ë³€í™˜
    BigKinds í˜ì´ì§€ë¥¼ ìŠ¤í¬ë˜í•‘í•˜ì—¬ "ì–¸ë¡ ì‚¬URL" ë²„íŠ¼ì˜ ë§í¬ë¥¼ ì¶”ì¶œ
    """
    if not news_id:
        return ''
    
    try:
        # BigKinds ê¸°ì‚¬ ìƒì„¸ í˜ì´ì§€ URL
        bigkinds_url = f"https://www.bigkinds.or.kr/v2/news/newsDetailView.do?newsId={news_id}"
        
        # í˜ì´ì§€ ìš”ì²­
        response = requests.get(bigkinds_url, timeout=10)
        if response.status_code != 200:
            print(f"   âš ï¸ BigKinds í˜ì´ì§€ ë¡œë“œ ì‹¤íŒ¨: {news_id}")
            return bigkinds_url
        
        # HTML íŒŒì‹±í•˜ì—¬ ì–¸ë¡ ì‚¬URL ë²„íŠ¼ ì°¾ê¸°
        import re
        # <button ... onclick="location.href='URL'">ì–¸ë¡ ì‚¬URL</button> íŒ¨í„´ ì°¾ê¸°
        match = re.search(r"onclick=\"location\.href='([^']+)'\"[^>]*>ì–¸ë¡ ì‚¬URL", response.text)
        if match:
            provider_url = match.group(1)
            # ?ref=kpf íŒŒë¼ë¯¸í„° ì œê±°
            provider_url = provider_url.split('?')[0]
            print(f"   âœ… ìŠ¤í¬ë˜í•‘ ì„±ê³µ: {provider_url}")
            return provider_url
        else:
            print(f"   âš ï¸ ì–¸ë¡ ì‚¬URL ë²„íŠ¼ ëª» ì°¾ìŒ: {news_id}")
            return bigkinds_url
            
    except Exception as e:
        print(f"   âš ï¸ ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {str(e)}")
        # fallback: BigKinds URL ë°˜í™˜
        return f"https://www.bigkinds.or.kr/v2/news/newsDetailView.do?newsId={news_id}"


def load_prompt_files(step_dir):
    """í”„ë¡¬í”„íŠ¸, ì§€ì¹¨, ë©”ëª¨ë¦¬, íŒŒì¼ë“¤ ë¡œë“œ"""
    prompt = (step_dir / 'prompt.txt').read_text(encoding='utf-8')
    instructions = (step_dir / 'instructions.txt').read_text(encoding='utf-8')
    memory = (step_dir / 'memory.txt').read_text(encoding='utf-8')
    
    # files ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  íŒŒì¼ ë¡œë“œ
    files_dir = step_dir / 'files'
    reference_files = {}
    if files_dir.exists():
        for file_path in files_dir.glob('*.txt'):
            reference_files[file_path.name] = file_path.read_text(encoding='utf-8')
    
    return {
        'prompt': prompt,
        'instructions': instructions,
        'memory': memory,
        'reference_files': reference_files
    }


def fetch_bigkinds_news(count=12):
    """BigKinds APIì—ì„œ ìµœê·¼ ê²½ì œ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°"""
    print(f"\nğŸ“° BigKinds APIì—ì„œ ë‰´ìŠ¤ {count}ê°œ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
    
    if not BIGKINDS_API_KEY:
        raise ValueError("BIGKINDS_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    end_date = datetime.now()
    start_date = end_date - timedelta(days=7)
    
    payload = {
        'access_key': BIGKINDS_API_KEY,
        'argument': {
            'query': '',
            'published_at': {
                'from': start_date.strftime('%Y-%m-%d'),
                'until': end_date.strftime('%Y-%m-%d')
            },
            'provider': ['ì„œìš¸ê²½ì œ'],
            'category': ['ê²½ì œ'],
            'sort': {'date': 'desc'},
            'hilight': 200,
            'return_from': 0,
            'return_size': count,
            'fields': ['title', 'content', 'published_at', 'provider', 'category', 'hilight', 'news_id', 'url', 'byline', 'provider_link_page']  # ì¶”ê°€ í•„ë“œ ìš”ì²­
        }
    }
    
    try:
        response = requests.post(
            'https://tools.kinds.or.kr/search/news',
            json=payload,
            headers={'Content-Type': 'application/json'},
            timeout=15
        )
        
        if response.status_code != 200:
            print(f"âŒ API ì‘ë‹µ ì½”ë“œ: {response.status_code}")
            raise Exception(f"BigKinds API ì˜¤ë¥˜: {response.status_code}")
        
        data = response.json()
        
        if data.get('result') != 0:
            print(f"âŒ API result ì½”ë“œ: {data.get('result')}")
            raise Exception(f"BigKinds API returned error result: {data.get('result')}")
        
        articles = data.get('return_object', {}).get('documents', [])
        
        print(f"âœ… {len(articles)}ê°œ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸° ì™„ë£Œ")
        return articles
        
    except requests.exceptions.JSONDecodeError as e:
        print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜")
        raise Exception(f"BigKinds API ì‘ë‹µì´ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤: {str(e)}")


def call_claude(system_prompt, user_prompt, max_tokens=4000):
    """AWS Bedrock Claude í˜¸ì¶œ"""
    request_body = {
        "anthropic_version": "bedrock-2023-05-31",
        "max_tokens": max_tokens,
        "system": system_prompt,
        "messages": [
            {
                "role": "user",
                "content": user_prompt
            }
        ],
        "temperature": 0.7,
        "top_p": 0.9
    }
    
    response = bedrock.invoke_model(
        modelId=BEDROCK_MODEL_ID,
        body=json.dumps(request_body)
    )
    
    response_body = json.loads(response['body'].read())
    return response_body['content'][0]['text']


def step1_screen_articles(articles):
    """Step 1: ê¸°ì‚¬ ìŠ¤í¬ë¦¬ë‹"""
    print("\nğŸ” Step 1: ê¸°ì‚¬ ìŠ¤í¬ë¦¬ë‹ ì‹œì‘...")
    
    # í”„ë¡¬í”„íŠ¸ ë¡œë“œ
    prompt_dir = Path(__file__).parent / 'prompts' / 'step1'
    step1_data = load_prompt_files(prompt_dir)
    
    # System prompt êµ¬ì„±
    system_prompt = f"""
{step1_data['prompt']}

{step1_data['instructions']}

ì°¸ì¡° íŒŒì¼:
"""
    for filename, content in step1_data['reference_files'].items():
        system_prompt += f"\n### {filename}\n{content}\n"
    
    # User prompt êµ¬ì„±
    articles_text = ""
    for i, article in enumerate(articles, 1):
        articles_text += f"\n\n[ê¸°ì‚¬ {i}]\n"
        articles_text += f"ì œëª©: {article.get('title', '')}\n"
        articles_text += f"ë³¸ë¬¸: {article.get('content', '')[:1000]}...\n"
    
    user_prompt = f"""
{step1_data['memory']}

ë‹¤ìŒ {len(articles)}ê°œì˜ ê²½ì œ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ë¶„ì„í•˜ì—¬ ê²Œì„ë³„ë¡œ ì í•©í•œ ê¸°ì‚¬ë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”.

**ì¤‘ìš”: ê° ê²Œì„ë³„ë¡œ ë°˜ë“œì‹œ 2ê°œì”©, ì´ 6ê°œ ê¸°ì‚¬ë¥¼ ì„ ì •í•´ì•¼ í•©ë‹ˆë‹¤.**
- ë¸”ë™ìŠ¤ì™„ ê²Œì„: 2ê°œ
- ì£„ìˆ˜ì˜ ë”œë ˆë§ˆ ê²Œì„: 2ê°œ
- ì‹œê·¸ë„ ë””ì½”ë”© ê²Œì„: 2ê°œ

{articles_text}

ë¶„ì„ ì‹œì‘
"""
    
    # Claude í˜¸ì¶œ
    response = call_claude(system_prompt, user_prompt, max_tokens=8000)
    
    print("âœ… Step 1 ì™„ë£Œ: ê¸°ì‚¬ ìŠ¤í¬ë¦¬ë‹ ê²°ê³¼ ìƒì„±")
    
    # ê¸°ì‚¬ ì œëª©-URL ë§¤í•‘ ìƒì„± (ì •ê·œí™”ëœ ì œëª©ìœ¼ë¡œ)
    article_url_map = {}
    article_url_map_normalized = {}  # ì •ê·œí™”ëœ ì œëª©ìœ¼ë¡œ ê²€ìƒ‰ìš©
    
    for article in articles:
        title = article.get('title', '')
        news_id = article.get('news_id', '')
        published_at = article.get('published_at', '')
        
        # provider_link_page í•„ë“œì—ì„œ ì„œìš¸ê²½ì œ ì›ë¬¸ URL ê°€ì ¸ì˜¤ê¸° (ìš°ì„ ìˆœìœ„ 1)
        url = article.get('provider_link_page', '')
        
        # provider_link_pageê°€ ì—†ìœ¼ë©´ news_idë¡œ BigKinds URL ìƒì„± (fallback)
        if not url:
            url = convert_newsid_to_sedaily_url(news_id)
        else:
            # ?ref=kpf íŒŒë¼ë¯¸í„° ì œê±° (ê¹”ë”í•œ URL)
            url = url.split('?')[0]
        
        if title:
            article_data = {
                'url': url,
                'publishedDate': published_at,
                'originalTitle': title
            }
            article_url_map[title] = article_data
            # ì •ê·œí™”ëœ ì œëª©ìœ¼ë¡œë„ ì €ì¥
            normalized_title = normalize_title(title)
            article_url_map_normalized[normalized_title] = article_data
    
    print(f"ğŸ“‹ URL ë§¤í•‘ ìƒì„± ì™„ë£Œ: {len(article_url_map)}ê°œ ê¸°ì‚¬")
    
    return response, (article_url_map, article_url_map_normalized)


def step2_generate_quiz(selected_articles, retry_count=0, max_retries=2):
    """Step 2: ë¬¸ì œ ì œì‘ (í…ìŠ¤íŠ¸ í˜•ì‹)"""
    print(f"\nâœï¸ Step 2: ë¬¸ì œ ì œì‘ ì‹œì‘... (ì‹œë„ {retry_count + 1}/{max_retries + 1})")
    
    # í”„ë¡¬í”„íŠ¸ ë¡œë“œ
    prompt_dir = Path(__file__).parent / 'prompts' / 'step2'
    step2_data = load_prompt_files(prompt_dir)
    
    # System prompt êµ¬ì„± (JSON ìš”êµ¬ ì œê±°)
    system_prompt = f"""
{step2_data['prompt']}

{step2_data['instructions']}

ì°¸ì¡° íŒŒì¼:
"""
    for filename, content in step2_data['reference_files'].items():
        system_prompt += f"\n### {filename}\n{content}\n"
    
    # User prompt êµ¬ì„±
    user_prompt = f"""
{step2_data['memory']}

ë‹¤ìŒì€ 1ë‹¨ê³„ ìŠ¤í¬ë¦¬ë‹ ê²°ê³¼ì…ë‹ˆë‹¤.

{selected_articles}

ìœ„ ìŠ¤í¬ë¦¬ë‹ ê²°ê³¼ì—ì„œ ì¶”ì²œëœ ê¸°ì‚¬ë“¤ì„ ì‚¬ìš©í•˜ì—¬ ì´ 6ê°œ ë¬¸ì œë¥¼ ì œì‘í•˜ì„¸ìš”.
(ë¸”ë™ìŠ¤ì™„ 2ê°œ, ì£„ìˆ˜ì˜ ë”œë ˆë§ˆ 2ê°œ, ì‹œê·¸ë„ ë””ì½”ë”© 2ê°œ)
"""
    
    # Claude í˜¸ì¶œ
    response = call_claude(system_prompt, user_prompt, max_tokens=8000)
    
    print("âœ… Step 2 ì™„ë£Œ: 6ê°œ ë¬¸ì œ ìƒì„±")
    return response


def clean_text(text):
    """í…ìŠ¤íŠ¸ì—ì„œ ì´ë¯¸ì§€ì™€ URL ì œê±°"""
    import re
    
    # ì´ë¯¸ì§€ ê´€ë ¨ íŒ¨í„´ ì œê±°
    text = re.sub(r'!\[.*?\]\(.*?\)', '', text)  # Markdown ì´ë¯¸ì§€
    text = re.sub(r'<img[^>]*>', '', text)  # HTML ì´ë¯¸ì§€
    text = re.sub(r'\[ì´ë¯¸ì§€.*?\]', '', text)  # [ì´ë¯¸ì§€] í…ìŠ¤íŠ¸
    text = re.sub(r'\(ì‚¬ì§„.*?\)', '', text)  # (ì‚¬ì§„...) í…ìŠ¤íŠ¸
    
    # URL ì œê±° (https://www.sedaily.com ë“±)
    text = re.sub(r'https?://[^\s]+', '', text)
    
    # ì—°ì†ëœ ê³µë°± ì •ë¦¬
    text = re.sub(r'\s+', ' ', text)
    
    return text.strip()


def parse_quiz_output(quiz_text, article_url_map, article_url_map_normalized):
    """í€´ì¦ˆ ì¶œë ¥ í…ìŠ¤íŠ¸ íŒŒì‹± (í…ìŠ¤íŠ¸ í˜•ì‹)"""
    print("\nğŸ”„ í€´ì¦ˆ ë°ì´í„° íŒŒì‹± ì¤‘...")
    
    import re
    
    def find_article_url(article_title):
        """ê¸°ì‚¬ ì œëª©ìœ¼ë¡œ URL ì°¾ê¸° (ì •ê·œí™” ë§¤ì¹­ í¬í•¨)"""
        article_title_clean = clean_text(article_title.strip())
        
        # 1ì°¨: ì •í™•í•œ ì œëª© ë§¤ì¹­
        if article_title_clean in article_url_map:
            return article_url_map[article_title_clean]
        
        # 2ì°¨: ì •ê·œí™”ëœ ì œëª© ë§¤ì¹­
        normalized = normalize_title(article_title_clean)
        if normalized in article_url_map_normalized:
            return article_url_map_normalized[normalized]
        
        # 3ì°¨: ë¶€ë¶„ ë§¤ì¹­ (ì œëª©ì˜ ì•ë¶€ë¶„ì´ ì¼ì¹˜í•˜ëŠ” ê²½ìš°)
        for original_title, article_data in article_url_map.items():
            if article_title_clean[:30] in original_title or original_title[:30] in article_title_clean:
                print(f"   âš ï¸ ë¶€ë¶„ ë§¤ì¹­: '{article_title_clean[:40]}...' â‰ˆ '{original_title[:40]}...'")
                return article_data
        
        # 4ì°¨: ë” ì§§ì€ ë¶€ë¶„ ë§¤ì¹­ (15ì)
        for original_title, article_data in article_url_map.items():
            if len(article_title_clean) >= 15 and len(original_title) >= 15:
                if article_title_clean[:15] in original_title or original_title[:15] in article_title_clean:
                    print(f"   âš ï¸ ì§§ì€ ë¶€ë¶„ ë§¤ì¹­: '{article_title_clean[:40]}...' â‰ˆ '{original_title[:40]}...'")
                    return article_data
        
        # 5ì°¨: í‚¤ì›Œë“œ ë§¤ì¹­ (ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬ëœ ë‹¨ì–´ ì¤‘ 3ê°œ ì´ìƒ ì¼ì¹˜)
        article_words = set(article_title_clean.split())
        for original_title, article_data in article_url_map.items():
            original_words = set(original_title.split())
            common_words = article_words & original_words
            if len(common_words) >= 3:
                print(f"   âš ï¸ í‚¤ì›Œë“œ ë§¤ì¹­ ({len(common_words)}ê°œ): '{article_title_clean[:40]}...' â‰ˆ '{original_title[:40]}...'")
                return article_data
        
        print(f"   âŒ URL ëª» ì°¾ìŒ: '{article_title_clean[:50]}...'")
        print(f"      ì‚¬ìš© ê°€ëŠ¥í•œ ê¸°ì‚¬ ì œëª©ë“¤:")
        for i, title in enumerate(list(article_url_map.keys())[:3], 1):
            print(f"      {i}. {title[:60]}...")
        
        return {}
    
    import re
    
    try:
        quiz_data = {
            'BlackSwan': [],
            'PrisonersDilemma': [],
            'SignalDecoding': []
        }
        
        # ì •ë‹µ ë° í•´ì„¤ ì„¹ì…˜ ì¶”ì¶œ
        answer_section = ""
        answer_match = re.search(r'ğŸ“‹ ì •ë‹µ ë° í•´ì„¤(.*?)(?:â”â”â”|ğŸ’¡|$)', quiz_text, re.DOTALL)
        if answer_match:
            answer_section = answer_match.group(1)
        
        # ê²Œì„ë³„ ì •ë‹µ ë° í•´ì„¤ ì¶”ì¶œ
        answers_explanations = {
            'BlackSwan': [],
            'PrisonersDilemma': [],
            'SignalDecoding': []
        }
        
        # ë¸”ë™ìŠ¤ì™„ ì •ë‹µ ì¶”ì¶œ
        bs_answers = re.findall(r'\*\*ë¸”ë™ìŠ¤ì™„: ([â‘ â‘¡â‘¢â‘£])\*\*\s*(.*?)(?=\*\*|$)', answer_section, re.DOTALL)
        for ans_symbol, explanation in bs_answers:
            correct_idx = ['â‘ ', 'â‘¡', 'â‘¢', 'â‘£'].index(ans_symbol)
            answers_explanations['BlackSwan'].append({
                'correctAnswer': correct_idx,
                'explanation': explanation.strip()
            })
        
        # ì£„ìˆ˜ì˜ ë”œë ˆë§ˆ ì •ë‹µ ì¶”ì¶œ
        pd_answers = re.findall(r'\*\*ì£„ìˆ˜ì˜ ë”œë ˆë§ˆ: ([â‘ â‘¡â‘¢â‘£])\*\*\s*(.*?)(?=\*\*|$)', answer_section, re.DOTALL)
        for ans_symbol, explanation in pd_answers:
            correct_idx = ['â‘ ', 'â‘¡', 'â‘¢', 'â‘£'].index(ans_symbol)
            answers_explanations['PrisonersDilemma'].append({
                'correctAnswer': correct_idx,
                'explanation': explanation.strip()
            })
        
        # ì‹œê·¸ë„ ë””ì½”ë”© ì •ë‹µ ì¶”ì¶œ
        sd_answers = re.findall(r'\*\*ì‹œê·¸ë„ ë””ì½”ë”©: ([â‘ â‘¡â‘¢â‘£])\*\*\s*(.*?)(?=\*\*|$)', answer_section, re.DOTALL)
        for ans_symbol, explanation in sd_answers:
            correct_idx = ['â‘ ', 'â‘¡', 'â‘¢', 'â‘£'].index(ans_symbol)
            answers_explanations['SignalDecoding'].append({
                'correctAnswer': correct_idx,
                'explanation': explanation.strip()
            })
        
        # ë¬¸ì œ ì„¹ì…˜ ì¶”ì¶œ (ë¸”ë™ìŠ¤ì™„)
        bs_problems = re.findall(r'ğŸŒŠ ë¸”ë™ìŠ¤ì™„.*?\n\n(.*?)\n\nâ‘ \s*(.*?)\nâ‘¡\s*(.*?)\nâ‘¢\s*(.*?)\nâ‘£\s*(.*?)\n\nğŸ“° ê´€ë ¨ ê¸°ì‚¬:\s*(.*?)\nğŸ“\s*"(.*?)"', quiz_text, re.DOTALL)
        for idx, (question, opt1, opt2, opt3, opt4, article_title, article_summary) in enumerate(bs_problems):
            if idx < len(answers_explanations['BlackSwan']):
                article_info = find_article_url(article_title)
                article_title_clean = article_info.get('originalTitle', clean_text(article_title.strip()))
                url = article_info.get('url', '')
                
                if not url:
                    print(f"   âš ï¸ ë¸”ë™ìŠ¤ì™„ ë¬¸ì œ {idx+1} URL ëª» ì°¾ìŒ: {article_title[:50]}...")
                else:
                    print(f"   âœ… ë¸”ë™ìŠ¤ì™„ ë¬¸ì œ {idx+1} URL: {url}")
                
                quiz_data['BlackSwan'].append({
                    'question': clean_text(question.strip()),
                    'options': [clean_text(opt1.strip()), clean_text(opt2.strip()), clean_text(opt3.strip()), clean_text(opt4.strip())],
                    'correctAnswer': answers_explanations['BlackSwan'][idx]['correctAnswer'],
                    'explanation': clean_text(answers_explanations['BlackSwan'][idx]['explanation']),
                    'newsLink': url,
                    'relatedArticle': {
                        'title': article_title_clean,
                        'excerpt': clean_text(article_summary.strip())
                    }
                })
        
        # ë¬¸ì œ ì„¹ì…˜ ì¶”ì¶œ (ì£„ìˆ˜ì˜ ë”œë ˆë§ˆ)
        pd_problems = re.findall(r'âš–ï¸ ì£„ìˆ˜ì˜ ë”œë ˆë§ˆ.*?\n\n(.*?)\n\nâ‘ \s*(.*?)\nâ‘¡\s*(.*?)\nâ‘¢\s*(.*?)\nâ‘£\s*(.*?)\n\nğŸ“° ê´€ë ¨ ê¸°ì‚¬:\s*(.*?)\nğŸ“\s*"(.*?)"', quiz_text, re.DOTALL)
        for idx, (question, opt1, opt2, opt3, opt4, article_title, article_summary) in enumerate(pd_problems):
            if idx < len(answers_explanations['PrisonersDilemma']):
                article_info = find_article_url(article_title)
                article_title_clean = article_info.get('originalTitle', clean_text(article_title.strip()))
                url = article_info.get('url', '')
                
                if not url:
                    print(f"   âš ï¸ ì£„ìˆ˜ì˜ ë”œë ˆë§ˆ ë¬¸ì œ {idx+1} URL ëª» ì°¾ìŒ: {article_title[:50]}...")
                else:
                    print(f"   âœ… ì£„ìˆ˜ì˜ ë”œë ˆë§ˆ ë¬¸ì œ {idx+1} URL: {url}")
                
                quiz_data['PrisonersDilemma'].append({
                    'question': clean_text(question.strip()),
                    'options': [clean_text(opt1.strip()), clean_text(opt2.strip()), clean_text(opt3.strip()), clean_text(opt4.strip())],
                    'correctAnswer': answers_explanations['PrisonersDilemma'][idx]['correctAnswer'],
                    'explanation': clean_text(answers_explanations['PrisonersDilemma'][idx]['explanation']),
                    'newsLink': url,
                    'relatedArticle': {
                        'title': article_title_clean,
                        'excerpt': clean_text(article_summary.strip())
                    }
                })
        
        # ë¬¸ì œ ì„¹ì…˜ ì¶”ì¶œ (ì‹œê·¸ë„ ë””ì½”ë”©)
        sd_problems = re.findall(r'ğŸ” ì‹œê·¸ë„ ë””ì½”ë”©.*?\n\n(.*?)\n\nâ‘ \s*(.*?)\nâ‘¡\s*(.*?)\nâ‘¢\s*(.*?)\nâ‘£\s*(.*?)\n\nğŸ“° ê´€ë ¨ ê¸°ì‚¬:\s*(.*?)\nğŸ“\s*"(.*?)"', quiz_text, re.DOTALL)
        for idx, (question, opt1, opt2, opt3, opt4, article_title, article_summary) in enumerate(sd_problems):
            if idx < len(answers_explanations['SignalDecoding']):
                article_info = find_article_url(article_title)
                article_title_clean = article_info.get('originalTitle', clean_text(article_title.strip()))
                url = article_info.get('url', '')
                
                if not url:
                    print(f"   âš ï¸ ì‹œê·¸ë„ ë””ì½”ë”© ë¬¸ì œ {idx+1} URL ëª» ì°¾ìŒ: {article_title[:50]}...")
                else:
                    print(f"   âœ… ì‹œê·¸ë„ ë””ì½”ë”© ë¬¸ì œ {idx+1} URL: {url}")
                
                quiz_data['SignalDecoding'].append({
                    'question': clean_text(question.strip()),
                    'options': [clean_text(opt1.strip()), clean_text(opt2.strip()), clean_text(opt3.strip()), clean_text(opt4.strip())],
                    'correctAnswer': answers_explanations['SignalDecoding'][idx]['correctAnswer'],
                    'explanation': clean_text(answers_explanations['SignalDecoding'][idx]['explanation']),
                    'newsLink': url,
                    'relatedArticle': {
                        'title': article_title_clean,
                        'excerpt': clean_text(article_summary.strip())
                    }
                })
        
        total_questions = sum(len(quiz_data.get(game, [])) for game in ['BlackSwan', 'PrisonersDilemma', 'SignalDecoding'])
        print(f"âœ… íŒŒì‹± ì™„ë£Œ (ì´ {total_questions}ê°œ ë¬¸ì œ)")
        
        for game in ['BlackSwan', 'PrisonersDilemma', 'SignalDecoding']:
            count = len(quiz_data.get(game, []))
            print(f"   - {game}: {count}ê°œ")
        
        return quiz_data
        
    except Exception as e:
        print(f"âš ï¸ íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()
        return {
            'BlackSwan': [],
            'PrisonersDilemma': [],
            'SignalDecoding': []
        }


def validate_quiz(quiz_data):
    """ìƒì„±ëœ í€´ì¦ˆ í’ˆì§ˆ ê²€ì¦"""
    print("\nğŸ” í’ˆì§ˆ ê²€ì¦ ì¤‘...")
    
    errors = []
    warnings = []
    
    # 1. ë¬¸ì œ ìˆ˜ í™•ì¸ (ì™„í™”: ìµœì†Œ 1ê°œ ì´ìƒ)
    for game in ['BlackSwan', 'PrisonersDilemma', 'SignalDecoding']:
        count = len(quiz_data.get(game, []))
        if count == 0:
            errors.append(f"{game}: ë¬¸ì œ ì—†ìŒ (ìµœì†Œ 1ê°œ í•„ìš”)")
        elif count != 2:
            warnings.append(f"{game}: {count}ê°œ ë¬¸ì œ (2ê°œ ê¶Œì¥)")
    
    # 2. í•„ìˆ˜ í•„ë“œ í™•ì¸ (í•„ìˆ˜)
    required_fields = ['question', 'options', 'correctAnswer']
    for game, questions in quiz_data.items():
        for i, q in enumerate(questions):
            for field in required_fields:
                if field not in q:
                    errors.append(f"{game} ë¬¸ì œ{i+1}: {field} í•„ë“œ ëˆ„ë½")
            # ì„ íƒì§€ ê°œìˆ˜ í™•ì¸
            if 'options' in q and len(q['options']) != 4:
                errors.append(f"{game} ë¬¸ì œ{i+1}: ì„ íƒì§€ {len(q['options'])}ê°œ (4ê°œ í•„ìš”)")
    
    # 3. ì •ë‹µ ë²ˆí˜¸ í™•ì¸ (ê²½ê³ ë§Œ)
    for game, questions in quiz_data.items():
        if len(questions) >= 2:
            answers = [q.get('correctAnswer') for q in questions]
            if len(set(answers)) < 2:
                warnings.append(f"{game}: ì •ë‹µ ë²ˆí˜¸ ì¤‘ë³µ ({answers}) - ê¶Œì¥í•˜ì§€ ì•Šì§€ë§Œ ì§„í–‰")
    
    is_valid = len(errors) == 0
    
    if is_valid:
        print("âœ… í’ˆì§ˆ ê²€ì¦ í†µê³¼")
        if warnings:
            print("âš ï¸ ê²½ê³ ì‚¬í•­:")
            for warning in warnings:
                print(f"   - {warning}")
    else:
        print(f"âŒ í’ˆì§ˆ ê²€ì¦ ì‹¤íŒ¨:")
        for error in errors:
            print(f"   - {error}")
    
    return is_valid, errors


def save_to_dynamodb(quiz_data, date):
    """DynamoDBì— í€´ì¦ˆ ì €ì¥"""
    print("\nğŸ’¾ DynamoDBì— ì €ì¥ ì¤‘...")
    
    table = dynamodb.Table(DYNAMODB_TABLE)
    
    # ê²Œì„ë³„ë¡œ ì €ì¥
    for game_type in ['BlackSwan', 'PrisonersDilemma', 'SignalDecoding']:
        questions = quiz_data.get(game_type, [])
        
        item = {
            'PK': f'QUIZ#{game_type}',
            'SK': f'DATE#{date}',
            'gameType': game_type,
            'date': date,  # ê¸°ì¡´ í•„ë“œëª… ìœ ì§€
            'questions': questions,
            'createdAt': datetime.now().isoformat(),
            'updatedAt': datetime.now().isoformat()
        }
        
        table.put_item(Item=item)
        print(f"  âœ… {game_type} ì €ì¥ ì™„ë£Œ ({len(questions)}ê°œ ë¬¸ì œ)")
    
    print("âœ… DynamoDB ì €ì¥ ì™„ë£Œ")
